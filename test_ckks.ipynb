{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "| Encryption parameters\n",
      "| scheme: ckks\n",
      "| poly_modulus_degree: 16384\n",
      "| coeff_modulus size: 420(60 + 50 + 50 + 50 + 50 + 50 + 50 + 60) bits\n",
      "\\\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/huyvu/workspace/thesis/SEAL-Python/')\n",
    "from seal import *\n",
    "from homomorphic_encryption_functions import dot_product_ciphertexts, eval_poly, sum_slots\n",
    "\n",
    "from homomorphic_encryption_functions import setup_ckks_params, create_tools\n",
    "from seal import *  # type: ignore\n",
    "\n",
    "poly_modulus_degree = 2**14\n",
    "coeff_modulus_chain = [60, 50, 50, 50, 50, 50, 50, 60]\n",
    "\n",
    "scale = 2.0 ** 50\n",
    "context = setup_ckks_params(poly_modulus_degree, coeff_modulus_chain)\n",
    "secret_key, public_key, relin_keys, galois_keys, encryptor, decryptor, evaluator, ckks_encoder = create_tools(context)\n",
    "slot_count = ckks_encoder.slot_count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_feature(df, encryptor, ckks_encoder, scale, slot_count):\n",
    "    \n",
    "    num_observations, num_columns = df.shape\n",
    "    slot_null = [0]*(slot_count - num_observations)\n",
    "    \n",
    "    bias_ptx = ckks_encoder.encode(np.concatenate(([1]*num_observations, slot_null)), scale)\n",
    "    bias_ctx = encryptor.encrypt(bias_ptx)\n",
    "    encrypted_data = [bias_ctx]\n",
    "    \n",
    "    # Apply batch encode to each column\n",
    "    for i in range(num_columns):\n",
    "        feature = df[:, i]\n",
    "        \n",
    "        feature_ptx = ckks_encoder.encode(np.concatenate((feature, slot_null)), scale)\n",
    "        feature_ctx = encryptor.encrypt(feature_ptx)\n",
    "            \n",
    "        encrypted_data.append(feature_ctx)\n",
    "    return encrypted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer_status</th>\n",
       "      <th>BRCA_status</th>\n",
       "      <th>Family_history_2</th>\n",
       "      <th>SNP2</th>\n",
       "      <th>SNP7</th>\n",
       "      <th>SNP13</th>\n",
       "      <th>SNP20</th>\n",
       "      <th>SNP24</th>\n",
       "      <th>SNP25</th>\n",
       "      <th>SNP32</th>\n",
       "      <th>SNP36</th>\n",
       "      <th>SNP41</th>\n",
       "      <th>SNP55</th>\n",
       "      <th>SNP58</th>\n",
       "      <th>SNP68</th>\n",
       "      <th>SNP81</th>\n",
       "      <th>SNP87</th>\n",
       "      <th>SNP92</th>\n",
       "      <th>SNP93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1579 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cancer_status  BRCA_status  Family_history_2  SNP2  SNP7  SNP13  SNP20  \\\n",
       "0                 0            0                 0     0     0      1      0   \n",
       "1                 0            0                 0     0     1      0      1   \n",
       "2                 0            0                 0     1     0      0      1   \n",
       "3                 1            0                 0     0     0      0      0   \n",
       "4                 1            0                 0     0     0      0      0   \n",
       "...             ...          ...               ...   ...   ...    ...    ...   \n",
       "1574              0            0                 0     1     0      1      0   \n",
       "1575              1            1                 0     0     0      0      1   \n",
       "1576              1            1                 0     0     0      0      0   \n",
       "1577              1            0                 0     0     1      1      1   \n",
       "1578              1            0                 0     0     1      1      1   \n",
       "\n",
       "      SNP24  SNP25  SNP32  SNP36  SNP41  SNP55  SNP58  SNP68  SNP81  SNP87  \\\n",
       "0         0      1      0      0      1      1      0      0      0      0   \n",
       "1         0      0      1      1      0      0      1      1      0      0   \n",
       "2         1      1      1      0      1      0      1      0      0      0   \n",
       "3         0      0      0      1      0      1      0      0      0      1   \n",
       "4         0      1      1      0      0      1      1      0      0      0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1574      0      0      0      0      1      0      0      0      1      1   \n",
       "1575      0      1      1      0      0      0      0      0      0      1   \n",
       "1576      1      0      1      0      0      0      0      0      0      0   \n",
       "1577      1      1      1      1      0      0      0      1      1      1   \n",
       "1578      1      1      0      0      1      0      1      1      1      1   \n",
       "\n",
       "      SNP92  SNP93  \n",
       "0         0      0  \n",
       "1         0      0  \n",
       "2         1      1  \n",
       "3         0      0  \n",
       "4         0      0  \n",
       "...     ...    ...  \n",
       "1574      0      1  \n",
       "1575      1      0  \n",
       "1576      0      0  \n",
       "1577      1      0  \n",
       "1578      0      0  \n",
       "\n",
       "[1579 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "iDASH_df = pd.read_csv(\"./data/idash.txt\")\n",
    "display(iDASH_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.002, num_iterations=100, momentum = 0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.momentum = momentum\n",
    "        \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 0.5 + 0.197*x - 0.004*(x**3)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        _, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "        velocity = np.zeros_like(self.weights)\n",
    "        \n",
    "        for _ in range(self.num_iterations):\n",
    "            lookahead_weights = self.weights + self.momentum * velocity\n",
    "            dot_X_W = np.dot(X, lookahead_weights)\n",
    "            y_predict = self.sigmoid(dot_X_W)\n",
    "            gradient =  np.dot((y_predict - y), X)\n",
    "            velocity = self.momentum * velocity - self.learning_rate * gradient\n",
    "            self.weights += velocity\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        linear_model = np.dot(X, self.weights) \n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "        linear_model = np.dot(X, self.weights)\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        return y_predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homomorphic_encryption_functions import dot_product_ciphertexts, eval_poly, sum_slots, switch_cipher_modulus\n",
    "\n",
    "\n",
    "class HELogisticRegression():   \n",
    "    \n",
    "    def __init__(self, learning_rate, momentum = 0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "         \n",
    "    def fit(self, X_ctx, y_ctx, w_ctx, v_ctx, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count):\n",
    "            \n",
    "            m_ptx = ckks_encoder.encode([self.momentum]*slot_count, scale)    \n",
    "            lookahead_weights = []\n",
    "            momen_volocity_arr = []\n",
    "            for i in range(len(v_ctx)):\n",
    "                momen_volocity = evaluator.multiply_plain(v_ctx[i], m_ptx)  # m*v 1\n",
    "                evaluator.relinearize_inplace(momen_volocity, relin_keys)\n",
    "                evaluator.rescale_to_next_inplace(momen_volocity)\n",
    "                momen_volocity.scale(scale)\n",
    "                momen_volocity_arr.append(momen_volocity)  \n",
    "                 \n",
    "                switch_weight = evaluator.mod_switch_to(w_ctx[i], momen_volocity.parms_id())\n",
    "                lookahead_weight = evaluator.add(switch_weight, momen_volocity)  # w + m*v \n",
    "                lookahead_weights.append(lookahead_weight) \n",
    "            \n",
    "            switched_X_ctx = switch_cipher_modulus(X_ctx, lookahead_weights[i].parms_id(), evaluator)\n",
    "            X_W = dot_product_ciphertexts(switched_X_ctx, lookahead_weights, scale, evaluator, relin_keys)  # X(w + m*v) #2\n",
    "            y_pred = eval_poly(X_W, ckks_encoder, scale, evaluator, relin_keys) # y^ 4\n",
    "            switched_y_ctx = evaluator.mod_switch_to(y_ctx, y_pred.parms_id()) \n",
    "            diff = evaluator.sub(y_pred, switched_y_ctx) # y^ - y\n",
    "        \n",
    "            new_w_ctx = []\n",
    "            new_v_ctx = [] \n",
    "  \n",
    "            for i in range(len(X_ctx)):\n",
    "                \n",
    "                switched_X = evaluator.mod_switch_to(X_ctx[i], diff.parms_id())  \n",
    "                dw = dot_product_ciphertexts([diff], [switched_X], scale, evaluator, relin_keys) # X(y^ - y) #5\n",
    "                sumslots_dw = sum_slots(dw, evaluator, galois_keys, slot_count) \n",
    "                \n",
    "                lr_ptx = ckks_encoder.encode([self.learning_rate], scale)\n",
    "                switched_lr_ptx = evaluator.mod_switch_to(lr_ptx, sumslots_dw.parms_id())\n",
    "                grad = evaluator.multiply_plain(sumslots_dw, switched_lr_ptx)  # alpha*X(y^ - y)#6\n",
    "                evaluator.relinearize_inplace(grad, relin_keys)\n",
    "                evaluator.rescale_to_next_inplace(grad)\n",
    "                grad.scale(scale)\n",
    "\n",
    "                switched_m_v = evaluator.mod_switch_to(momen_volocity_arr[i], grad.parms_id()) \n",
    "                switched_w = evaluator.mod_switch_to(w_ctx[i], grad.parms_id())\n",
    "                \n",
    "                new_v = evaluator.sub(switched_m_v, grad) # v = m*v - alpha*X(y^ - y)\n",
    "                new_v_ctx.append(new_v) \n",
    "                new_w = evaluator.add(switched_w, new_v) # w = w + v\n",
    "                new_w_ctx.append(new_w)\n",
    "            \n",
    "            \n",
    "            return new_v_ctx, new_w_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from homomorphic_encryption_functions import encrypt_label, encrypt_feature, encrypt_weights, decrypt_weights\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def decrypt_weights(encrypted_weights, ckks_encoder, decryptor):\n",
    "    weights = []\n",
    "    for weight_ctx in encrypted_weights:\n",
    "        weight_ptx = decryptor.decrypt(weight_ctx)\n",
    "        weight = ckks_encoder.decode(weight_ptx)\n",
    "\n",
    "        weights.append(weight[0])\n",
    "            \n",
    "    return weights\n",
    "def encrypt_weights(weights, ckks_encoder, scale, encryptor):\n",
    "    encrypted_weights = []\n",
    "    for weight in weights:\n",
    "        weight_ptx = ckks_encoder.encode([weight] * ckks_encoder.slot_count(), scale)\n",
    "        weight_ctx = encryptor.encrypt(weight_ptx)\n",
    "        encrypted_weights.append(weight_ctx)\n",
    "    \n",
    "    return encrypted_weights\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def predict(X, weights):\n",
    "    X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    linear_model = np.dot(X, weights) \n",
    "    proba = sigmoid(linear_model)\n",
    "    predict_label = [1 if i > 0.5 else 0 for i in proba]\n",
    "    return predict_label\n",
    "    \n",
    "def predict_proba(X, weights):\n",
    "    X = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    linear_model = np.dot(X, weights)\n",
    "    proba = sigmoid(linear_model)\n",
    "    return proba \n",
    "def average_accuracy_and_auc_score(model, X, y):\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    acc_scores = []\n",
    "    auc_scores = []\n",
    " \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        model.fit(X_train, y_train)\n",
    "        y_prob = model.predict_proba(X_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        acc_scores.append(acc)\n",
    "        auc_scores.append(auc)\n",
    "     \n",
    "    average_acc = np.mean(acc_scores) \n",
    "    average_auc = np.mean(auc_scores)\n",
    "    \n",
    "    return average_acc, average_auc\n",
    "\n",
    "\n",
    "def average_accuracy_and_auc_score_helr(model, n, X, y, encryptor, decryptor, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    auc_scores = []\n",
    "    acc_scores = []\n",
    "   \n",
    "    for train_index, test_index in kf.split(X):\n",
    "      \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_ctx = encrypt_feature(X_train, encryptor, ckks_encoder, scale, slot_count)\n",
    "        y_ctx = encrypt_label(y_train, encryptor, ckks_encoder, scale)\n",
    "\n",
    "        w = [0] * len(X_ctx)\n",
    "        w_ctx  = encrypt_weights(w, ckks_encoder, scale, encryptor)\n",
    "        v_ctx  = w_ctx\n",
    "        for _ in range(n):\n",
    "            new_v_ctx, new_w_ctx = model.fit(X_ctx, y_ctx, w_ctx, v_ctx,ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count)\n",
    "            new_v = decrypt_weights(new_v_ctx, ckks_encoder, decryptor)\n",
    "            new_w = decrypt_weights(new_w_ctx, ckks_encoder, decryptor)\n",
    "    \n",
    "            re_encrypted_w = encrypt_weights(new_w, ckks_encoder, scale, encryptor)\n",
    "            re_encrypted_v = encrypt_weights(new_v, ckks_encoder, scale, encryptor)\n",
    "            w_ctx = re_encrypted_w\n",
    "            v_ctx = re_encrypted_v\n",
    "        new_w = decrypt_weights(new_w_ctx, ckks_encoder, decryptor)\n",
    "        y_prob = predict_proba(X_test, new_w)\n",
    "        y_pred = predict(X_test, new_w)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        acc_scores.append(acc)\n",
    "        auc_scores.append(auc)    \n",
    "   \n",
    "\n",
    "    average_acc = np.mean(acc_scores)\n",
    "    average_auc = np.mean(auc_scores)\n",
    "    \n",
    "    return average_acc, average_auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from logistic_regression import average_accuracy_and_auc_score\n",
    "\n",
    "def prepare_data(df, target):\n",
    "    feature_names = df.columns.tolist()\n",
    "    feature_names.remove(target)\n",
    "    X = df[feature_names]\n",
    "    y = df[target]\n",
    "    return X.values , y\n",
    "\n",
    "\n",
    "X_idash, y_idash = prepare_data(iDASH_df, target = 'Cancer_status')\n",
    "\n",
    "import time\n",
    "def train_and_evaluate_models_performance(X, y, best_params, encryptor, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count):\n",
    "    \n",
    "    print(\"- Logistic Regression over unencrypted dataset...\")\n",
    "    lr = LogisticRegression(learning_rate=best_params['learning_rate'], num_iterations= best_params['num_iterations'], momentum=best_params['momentum'])\n",
    "    start_time = time.time()\n",
    "    avg_accuracy, avg_auc = average_accuracy_and_auc_score(lr, X, y) \n",
    "    end_time = time.time()\n",
    "    print(f\"\\t+ Total training time: {(end_time - start_time):.2f}s\")\n",
    "    print(f\"\\t+ Average accuracy score: {(avg_accuracy*100):.2f}%\")\n",
    "    print(f\"\\t+ Average auc score: {avg_auc:.4f}\")\n",
    "\n",
    "    print(\"\\n- Logistic Regression over encrypted dataset...\\n\")\n",
    "    num_iterations = best_params['num_iterations']\n",
    "    helr  = HELogisticRegression(learning_rate=best_params['learning_rate'], momentum=best_params['momentum'])\n",
    "    start_time = time.time()\n",
    "    avg_accuracy_helr, avg_auc_helr = average_accuracy_and_auc_score_helr(helr, num_iterations, X, y, encryptor, decryptor, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    minutes = int(execution_time // 60)\n",
    "    seconds = execution_time % 60\n",
    "    print(f\"\\t+ Total training time: {minutes}m{seconds:.2f}s\")\n",
    "    print(f\"\\t+ Average accuracy score: {(avg_accuracy_helr*100):.2f}%\")\n",
    "    print(f\"\\t+ Average auc score: {avg_auc_helr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.001, 'num_iterations': 20, 'momentum': 0.9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Logistic Regression over unencrypted dataset...\n",
      "\t+ Total training time: 0.44s\n",
      "\t+ Average accuracy score: 62.19%\n",
      "\t+ Average auc score: 0.6906\n",
      "\n",
      "- Logistic Regression over encrypted dataset...\n",
      "\n",
      "\t+ Total training time: 7m18.52s\n",
      "\t+ Average accuracy score: 62.19%\n",
      "\t+ Average auc score: 0.6910\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_models_performance(X_idash, y_idash, best_params, encryptor, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "heart_df = pd.read_csv(\"./data/heart.csv\")\n",
    "columns_name = ['age', 'trtbps', 'chol', 'thalachh']\n",
    "\n",
    "filled_heart_df = heart_df[columns_name]\n",
    "scaled_filled_diabetes = np.round(StandardScaler().fit_transform(filled_heart_df), 2)\n",
    "scaled_filled_heart_df = pd.DataFrame(scaled_filled_diabetes, columns=columns_name)\n",
    "heart_df[columns_name] = scaled_filled_heart_df\n",
    "heart_df\n",
    "X_heart, y_heart = prepare_data(heart_df, 'output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Logistic Regression over unencrypted dataset...\n",
      "\t+ Total training time: 0.11s\n",
      "\t+ Average accuracy score: 81.18%\n",
      "\t+ Average auc score: 0.8849\n",
      "\n",
      "- Logistic Regression over encrypted dataset...\n",
      "\n",
      "\t+ Total training time: 12m28.60s\n",
      "\t+ Average accuracy score: 81.19%\n",
      "\t+ Average auc score: 0.8835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_params = {'learning_rate': 0.001, 'num_iterations': 40, 'momentum': 0.3}\n",
    "train_and_evaluate_models_performance(X_heart, y_heart, best_params, encryptor, ckks_encoder, scale, evaluator, relin_keys, galois_keys, slot_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>Pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_187</th>\n",
       "      <th>Pixel_188</th>\n",
       "      <th>Pixel_189</th>\n",
       "      <th>Pixel_190</th>\n",
       "      <th>Pixel_191</th>\n",
       "      <th>Pixel_192</th>\n",
       "      <th>Pixel_193</th>\n",
       "      <th>Pixel_194</th>\n",
       "      <th>Pixel_195</th>\n",
       "      <th>Pixel_196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.509073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004032</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095189</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.083969</td>\n",
       "      <td>0.092523</td>\n",
       "      <td>0.044901</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label  Pixel_1  Pixel_2  Pixel_3  Pixel_4  Pixel_5  Pixel_6  \\\n",
       "count  1984.000000   1984.0   1984.0   1984.0   1984.0   1984.0   1984.0   \n",
       "mean      0.509073      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std       0.500044      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min       0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%       0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%       1.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%       1.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max       1.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "       Pixel_7  Pixel_8  Pixel_9  ...    Pixel_187    Pixel_188    Pixel_189  \\\n",
       "count   1984.0   1984.0   1984.0  ...  1984.000000  1984.000000  1984.000000   \n",
       "mean       0.0      0.0      0.0  ...     0.004032     0.002016     0.002520   \n",
       "std        0.0      0.0      0.0  ...     0.095189     0.054970     0.067322   \n",
       "min        0.0      0.0      0.0  ...     0.000000     0.000000     0.000000   \n",
       "25%        0.0      0.0      0.0  ...     0.000000     0.000000     0.000000   \n",
       "50%        0.0      0.0      0.0  ...     0.000000     0.000000     0.000000   \n",
       "75%        0.0      0.0      0.0  ...     0.000000     0.000000     0.000000   \n",
       "max        0.0      0.0      0.0  ...     3.000000     2.000000     2.000000   \n",
       "\n",
       "         Pixel_190    Pixel_191    Pixel_192    Pixel_193  Pixel_194  \\\n",
       "count  1984.000000  1984.000000  1984.000000  1984.000000     1984.0   \n",
       "mean      0.003024     0.003528     0.001008     0.000504        0.0   \n",
       "std       0.083969     0.092523     0.044901     0.022451        0.0   \n",
       "min       0.000000     0.000000     0.000000     0.000000        0.0   \n",
       "25%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
       "50%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
       "75%       0.000000     0.000000     0.000000     0.000000        0.0   \n",
       "max       3.000000     3.000000     2.000000     1.000000        0.0   \n",
       "\n",
       "       Pixel_195  Pixel_196  \n",
       "count     1984.0     1984.0  \n",
       "mean         0.0        0.0  \n",
       "std          0.0        0.0  \n",
       "min          0.0        0.0  \n",
       "25%          0.0        0.0  \n",
       "50%          0.0        0.0  \n",
       "75%          0.0        0.0  \n",
       "max          0.0        0.0  \n",
       "\n",
       "[8 rows x 197 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['label' if i == 0 else f'Pixel_{i}' for i in range(197)]\n",
    "MNIST_df = pd.read_csv(\"./data/mnist.csv\", header=None, names = columns)\n",
    "new_label = MNIST_df['label'].apply(lambda x: 0 if x == -1 else 1)\n",
    "MNIST_df['label'] = new_label\n",
    "def normalizeMNISTData(df):\n",
    "    columns = MNIST_df.columns.tolist()\n",
    "    columns.remove('label')\n",
    "    \n",
    "    for col in columns:\n",
    "        MNIST_df[col] =(MNIST_df[col]/32).astype('int32')\n",
    "        \n",
    "    return df\n",
    "\n",
    "normalized_MNIST_df = normalizeMNISTData(MNIST_df)\n",
    "normalized_MNIST_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Logistic Regression over unencrypted dataset...\n",
      "\t+ Total training time: 0.50s\n",
      "\t+ Average accuracy score: 94.46%\n",
      "\t+ Average auc score: 0.9859\n"
     ]
    }
   ],
   "source": [
    "X_mnist, y_mnist = prepare_data(normalized_MNIST_df, 'label')\n",
    "print(\"- Logistic Regression over unencrypted dataset...\")\n",
    "lr = LogisticRegression(learning_rate=1e-5, num_iterations= 10, momentum=0.5)\n",
    "start_time = time.time()\n",
    "avg_accuracy, avg_auc = average_accuracy_and_auc_score(lr, X_mnist, y_mnist) \n",
    "end_time = time.time()\n",
    "print(f\"\\t+ Total training time: {(end_time - start_time):.2f}s\")\n",
    "print(f\"\\t+ Average accuracy score: {(avg_accuracy*100):.2f}%\")\n",
    "print(f\"\\t+ Average auc score: {avg_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>1</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-1.31</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.11</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3654</th>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.49</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3656 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      male   age  education  currentSmoker  cigsPerDay  BPMeds  \\\n",
       "0        1 -1.23        4.0              0       -0.76     0.0   \n",
       "1        0 -0.42        2.0              0       -0.76     0.0   \n",
       "2        1 -0.18        1.0              1        0.92     0.0   \n",
       "3        0  1.34        3.0              1        1.76     0.0   \n",
       "4        0 -0.42        3.0              1        1.17     0.0   \n",
       "...    ...   ...        ...            ...         ...     ...   \n",
       "3651     1  0.99        3.0              0       -0.76     0.0   \n",
       "3652     1  2.15        1.0              0       -0.76     0.0   \n",
       "3653     1  0.05        1.0              1       -0.67     0.0   \n",
       "3654     1  0.17        3.0              1        2.85     0.0   \n",
       "3655     0  0.29        2.0              0       -0.76     0.0   \n",
       "\n",
       "      prevalentStroke  prevalentHyp  diabetes  totChol  sysBP  diaBP   BMI  \\\n",
       "0                   0             0         0    -0.95  -1.19  -1.08  0.29   \n",
       "1                   0             0         0     0.30  -0.51  -0.16  0.72   \n",
       "2                   0             0         0     0.18  -0.22  -0.24 -0.11   \n",
       "3                   0             1         0    -0.27   0.80   1.01  0.69   \n",
       "4                   0             0         0     1.09  -0.11   0.09 -0.66   \n",
       "...               ...           ...       ...      ...    ...    ...   ...   \n",
       "3651                0             1         0    -1.13   0.39  -0.16 -0.20   \n",
       "3652                0             1         0    -1.38   1.61   1.18 -0.65   \n",
       "3653                0             1         0     1.73   2.11   0.76  0.05   \n",
       "3654                0             0         0    -0.68  -0.27  -0.24 -1.49   \n",
       "3655                0             0         0     0.73   0.05   0.01 -1.06   \n",
       "\n",
       "      heartRate  glucose  TenYearCHD  \n",
       "0          0.36    -0.20           0  \n",
       "1          1.61    -0.24           0  \n",
       "2         -0.06    -0.50           0  \n",
       "3         -0.90     0.88           1  \n",
       "4          0.77     0.13           0  \n",
       "...         ...      ...         ...  \n",
       "3651       0.36    -0.04           0  \n",
       "3652      -1.31    -0.12           1  \n",
       "3653      -0.81     0.17           1  \n",
       "3654      -0.90    -0.58           0  \n",
       "3655       0.36     1.05           0  \n",
       "\n",
       "[3656 rows x 16 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "framingham_df = pd.read_csv(\"./data/framingham.csv\")\n",
    "framingham_df = framingham_df.dropna().reset_index(drop=True)\n",
    "columns_name = framingham_df.columns\n",
    "columns_name = columns_name.drop(['male', 'education', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes', 'TenYearCHD'])\n",
    "\n",
    "filled_framingham_df = framingham_df[columns_name]\n",
    "scaled_filled_diabetes = np.round(StandardScaler().fit_transform(filled_framingham_df), 2)\n",
    "scaled_filled_framingham_df = pd.DataFrame(scaled_filled_diabetes, columns=columns_name)\n",
    "framingham_df[columns_name] = scaled_filled_framingham_df\n",
    "framingham_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import prepare_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_framingham, y_framingham = prepare_data(framingham_df, 'TenYearCHD')\n",
    "resampled_X_framingham, resampled_y_framingham = SMOTE().fit_resample(X_framingham, y_framingham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Logistic Regression over unencrypted dataset...\n",
      "\t+ Total training time: 0.66s\n",
      "\t+ Average accuracy score: 66.99%\n",
      "\t+ Average auc score: 0.7356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"- Logistic Regression over unencrypted dataset...\")\n",
    "lr = LogisticRegression(learning_rate=0.0001, num_iterations= 10)\n",
    "start_time = time.time()\n",
    "avg_accuracy, avg_auc = average_accuracy_and_auc_score(lr, resampled_X_framingham, resampled_y_framingham) \n",
    "end_time = time.time()\n",
    "print(f\"\\t+ Total training time: {(end_time - start_time):.2f}s\")\n",
    "print(f\"\\t+ Average accuracy score: {(avg_accuracy*100):.2f}%\")\n",
    "print(f\"\\t+ Average auc score: {avg_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"./data/diabetes.csv\")\n",
    "columns_name = diabetes_df.columns\n",
    "columns_name = columns_name.drop(['DiabetesPedigreeFunction', 'Outcome'])\n",
    "\n",
    "filled_diabetes_df = diabetes_df[columns_name]\n",
    "scaled_filled_diabetes = np.round(StandardScaler().fit_transform(filled_diabetes_df),3)\n",
    "scaled_filled_diabetes_df = pd.DataFrame(scaled_filled_diabetes, columns=columns_name)\n",
    "diabetes_df[columns_name] = scaled_filled_diabetes_df\n",
    "X_diabetes, y_diabetes = prepare_data(diabetes_df, 'Outcome')\n",
    "resampled_X_diabetes, resampled_y_diabetes = SMOTE().fit_resample(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Logistic Regression over unencrypted dataset...\n",
      "\t+ Total training time: 0.06s\n",
      "\t+ Average accuracy score: 73.00%\n",
      "\t+ Average auc score: 0.8142\n"
     ]
    }
   ],
   "source": [
    "print(\"- Logistic Regression over unencrypted dataset...\")\n",
    "lr = LogisticRegression(learning_rate=0.0001, num_iterations= 10)\n",
    "start_time = time.time()\n",
    "avg_accuracy, avg_auc = average_accuracy_and_auc_score(lr, resampled_X_diabetes, resampled_y_diabetes) \n",
    "end_time = time.time()\n",
    "print(f\"\\t+ Total training time: {(end_time - start_time):.2f}s\")\n",
    "print(f\"\\t+ Average accuracy score: {(avg_accuracy*100):.2f}%\")\n",
    "print(f\"\\t+ Average auc score: {avg_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
